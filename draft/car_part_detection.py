# -*- coding: utf-8 -*-
"""car_part_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1axucSB5na0mQx7ojfdWiNEkftTdC66n3

## Setup project
"""

!rm -rf Car-Parts-Segmentation/ project labels images dataset

!git clone https://github.com/sanayasfp/Car-Parts-Segmentation.git

"""## Generate dataset"""

import os
import shutil
import json

def create_dataset_structure(path: str):
  dataset_path = os.path.join(path, "dataset")

  if not os.path.exists(dataset_path):
    os.makedirs(dataset_path, True)

  images_path = os.path.join(dataset_path, "images")
  labels_path = os.path.join(dataset_path, "labels")

  if not os.path.exists(images_path):
    os.makedirs(images_path, True)

  if not os.path.exists(labels_path):
    os.makedirs(labels_path, True)

  for path in [images_path, labels_path]:
    for d in ["train", "val", "test"]:
      if not os.path.exists(os.path.join(path, d)):
        os.makedirs(os.path.join(path, d), True)

  return dataset_path, images_path, labels_path

def write_yolo_labels(anotations_for_image, categories, image_name, image_width, image_height, labels_path):
  file_name = image_name.split(".")[0]

  with open(os.path.join(labels_path, "{}.txt".format(file_name)), "w") as f:
    for index, annotation in enumerate(anotations_for_image):
      category_id = annotation["category_id"]
      category = next(filter(lambda x: x["id"] == category_id, categories))
      class_name = category["name"]
      class_id = category["id"] -2

      if class_id < 0:
        continue

      bbox = annotation["bbox"]

      x_center = (bbox[0] + bbox[2] / 2) / image_width
      y_center = (bbox[1] + bbox[3] / 2) / image_height
      width = bbox[2] / image_width
      height = bbox[3] / image_height

      newline = "\n" if index != len(anotations_for_image) - 1 else ""

      f.write("{} {} {} {} {}{}".format(class_id, x_center, y_center, width, height, newline))

    f.close()
    return class_id, class_name

def anotate_image(dataset_path, image_dest_path: str, labels_path: str, part: str = "train"):
  anotation_file_path = os.path.join(dataset_path, "annotations.json")

  if not os.path.exists(anotation_file_path):
    raise ValueError(f'File {anotation_file_path} does not exist')

  model_class: set(tuple) = set()

  with open(anotation_file_path, "r") as f:
    anotation_data = json.load(f)

    for image in anotation_data["images"]:
      image_name = image["file_name"]
      image_id = image["id"]
      image_width = image["width"]
      image_height = image["height"]
      image_path = os.path.join(dataset_path, image["path"])
      anotations_for_image = [a for a in anotation_data["annotations"] if a["image_id"] == image_id]

      if not os.path.exists(image_path):
        continue

      shutil.copy2(image_path, os.path.join(image_dest_path, part, image_name))
      class_id, class_name = write_yolo_labels(
          anotations_for_image,
          anotation_data["categories"],
          image_name,
          image_width,
          image_height,
          os.path.join(labels_path, part)
      )
      model_class.add((class_id, class_name))

    f.close()
    return model_class

def sort_model_class(model_class):
  return sorted(model_class, key=lambda x: x[0])

def generate_dataset(path: str = "."):
  _, images_path, labels_path = create_dataset_structure(path)
  trainset_path = "Car-Parts-Segmentation/trainingset"
  testset_path = "Car-Parts-Segmentation/testset"

  dataset_part = ["train", "test"]
  dataset = {}

  for index, path in enumerate([trainset_path, testset_path]):
    model_class = anotate_image(path, images_path, labels_path, dataset_part[index])
    dataset[dataset_part[index]] = sort_model_class(model_class)

  return dataset

dataset_class = generate_dataset("project")

"""## Generate Config file (config.yml)"""

def generate_dataset_config(dataset_class: dict, path: str = "."):
  dataset_path = os.path.join(os.path.abspath(path), "dataset")
  config_path = os.path.join(dataset_path, "config.yaml")
  part = dataset_class.keys()

  if not "train" in part:
    raise ValueError("Train set not found")

  model_class = dataset_class['train']
  train = "images/train"
  val = "images/val" if "val" in part else train
  test = "images/test" if "test" in part else val

  with open(config_path, "w") as f:
    f.write(f"path: {dataset_path}\n")
    f.write(f"train: {train}\n")
    f.write(f"val: {val}\n")
    f.write(f"test: {test}\n")
    f.write("nc: {}\n".format(len(model_class)))
    f.write("names: \n")

    for class_id, class_name in model_class:
      f.write(f"  {class_id}: {class_name}\n")

    f.close()

generate_dataset_config(dataset_class, "./project")

"""## Train model"""

!pip install ultralytics

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

results = model.train(data="/content/project/dataset/config.yaml", epochs=1)

results.

"""## Validate model"""

!yolo task=detect \
mode=val \
model=./runs/detect/train/weights/best.pt \
data=./project/dataset/config.yaml

"""Predict with model"""

!yolo task=detect \
mode=predict \
model=./runs/detect/train/weights/best.pt \
conf=0.25 \
source=./project/dataset/images/test/

!yolo task=detect \
mode=predict \
model=./runs/detect/train/weights/best.pt \
conf=0.25 \
source=./project/ressources/front.jpeg